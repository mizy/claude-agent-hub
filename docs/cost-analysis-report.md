# CAH 对话系统 Token 消耗与费用分析报告

> 分析时间：2026-02-12 | 基于当前代码库源码静态分析

## 1. API 定价基准

| 模型 | Input ($/MTok) | Output ($/MTok) | Cache Write ($/MTok) | Cache Hit ($/MTok) |
|------|---------------|-----------------|---------------------|-------------------|
| Opus 4.6 | $5.00 | $25.00 | $6.25 (5min) | $0.50 |
| Sonnet 4.5 | $3.00 | $15.00 | $3.75 (5min) | $0.30 |
| Haiku 4.5 | $1.00 | $5.00 | $1.25 (5min) | $0.10 |

**关键换算**：1 token ≈ 4 英文字符 ≈ 1.5-2 中文字符

---

## 2. 各场景 Token 消耗明细

### 场景 A：聊天首次消息（无 session）

新会话时，prompt = `clientPrefix` + `historyContext` + `userMessage`

| 组成部分 | 字符数估算 | Token 数估算 | 说明 |
|---------|-----------|-------------|------|
| `buildClientPrompt()` 基础 | ~1,800 字符 | ~900 tokens | 自我意识 + 人设 + 行为准则 + 任务分流规则 |
| 飞书格式注入 | ~200 字符 | ~100 tokens | 飞书平台额外格式约束 |
| `historyContext`（20条消息） | ~4,000 字符 | ~2,000 tokens | 每条截取200字，20条 × ~200字 |
| 用户消息 | ~100 字符 | ~50 tokens | 典型短消息 |
| **Input 合计** | **~6,100 字符** | **~3,050 tokens** | |
| AI 回复（Output） | ~800 字符 | ~400 tokens | 典型简短回复 |

**首次消息费用估算**：

| 模型 | Input 费用 | Output 费用 | 单次总费用 |
|------|-----------|------------|-----------|
| Opus 4.6 | $0.0153 | $0.0100 | **$0.0253** |
| Sonnet 4.5 | $0.0092 | $0.0060 | **$0.0152** |

### 场景 B：聊天后续消息（有 session）

Session 存在时，Claude Code 使用 `--resume sessionId`，内部维护上下文。CAH 仍然发送完整 prompt（包含 clientPrefix），但 Claude Code 的 prompt caching 机制会缓存 system prompt。

| 组成部分 | 字符数估算 | Token 数估算 | 说明 |
|---------|-----------|-------------|------|
| `buildClientPrompt()` | ~1,800 字符 | ~900 tokens | 同上，但大概率命中 cache |
| historyContext | 0 | 0 | 有 sessionId 时跳过 |
| 用户消息 | ~100 字符 | ~50 tokens | |
| **Input 合计** | **~1,900 字符** | **~950 tokens** | |
| Claude Code 内部上下文 | 不可控 | ~5,000-50,000 tokens | 随对话轮次累积（tool calls、文件内容等） |
| AI 回复（Output） | ~800 字符 | ~400 tokens | |

**后续消息费用估算**（不含 Claude Code 内部上下文）：

| 模型 | Input 费用 | Output 费用 | 单次总费用 |
|------|-----------|------------|-----------|
| Opus 4.6 | $0.0048 | $0.0100 | **$0.0148** |
| Sonnet 4.5 | $0.0029 | $0.0060 | **$0.0089** |

> **注意**：实际费用远高于此，因为 Claude Code 内部会自动使用工具（Read、Grep、Bash 等），每次工具调用都产生大量 token。一次典型的对话交互实际消耗约 $0.02-0.15（sonnet）或 $0.03-0.25（opus）。

### 场景 C：任务工作流生成

`buildJsonWorkflowPrompt()` 构建的完整 prompt：

| 组成部分 | 字符数估算 | Token 数估算 | 占比 |
|---------|-----------|-------------|------|
| 固定框架文本（角色+原则+节点类型+规则） | ~6,500 字符 | ~3,250 tokens | 35% |
| Agent Teams 指令（可选） | ~800 字符 | ~400 tokens | 4% |
| `agentDescriptions`（9个 persona） | ~600 字符 | ~300 tokens | 3% |
| `projectContext`（formatProjectContextForPrompt） | ~2,000 字符 | ~1,000 tokens | 11% |
| 其中 CLAUDE.md 截取前1000字 | ~1,000 字符 | ~500 tokens | |
| `learningInsights`（formatInsightsForPrompt） | ~1,500 字符 | ~750 tokens | 8% |
| `memoryContext` | ~500 字符 | ~250 tokens | 3% |
| 任务描述 + 元信息 | ~300 字符 | ~150 tokens | 2% |
| **Input 合计** | **~12,200 字符** | **~6,100 tokens** | **100%** |
| AI 输出（JSON workflow） | ~3,000 字符 | ~1,500 tokens | |

**工作流生成费用**：

| 模型 | Input 费用 | Output 费用 | 单次总费用 |
|------|-----------|------------|-----------|
| Opus 4.6 | $0.0305 | $0.0375 | **$0.0680** |
| Sonnet 4.5 | $0.0183 | $0.0225 | **$0.0408** |

### 场景 D：节点执行

`buildExecuteNodePrompt()` + Claude Code 实际执行（读文件、写文件、运行命令）：

| 组成部分 | 字符数估算 | Token 数估算 | 说明 |
|---------|-----------|-------------|------|
| Persona systemPrompt | ~300 字符 | ~150 tokens | 如 Pragmatist ~300字 |
| 节点模板框架 | ~200 字符 | ~100 tokens | 时间、目录、节点名 |
| nodePrompt（任务描述） | ~500 字符 | ~250 tokens | 用户定义的节点任务 |
| context（已完成节点信息） | ~800 字符 | ~400 tokens | 前置节点输出摘要 |
| **显式 Input 合计** | **~1,800 字符** | **~900 tokens** | 仅初始 prompt |
| Claude Code 工具调用 | 不可控 | ~20,000-100,000 tokens | 读文件、搜索、编辑、运行命令 |
| AI 输出 | ~5,000 字符 | ~2,500 tokens | |

**节点执行费用**（实际值，含 Claude Code 内部消耗）：

| 模型 | 典型费用范围 | 说明 |
|------|------------|------|
| Opus 4.6 | **$0.10 - $1.50** | 复杂节点可能读取大量文件 |
| Sonnet 4.5 | **$0.06 - $0.90** | |

> 节点执行是整个系统中费用最高的场景，因为 Claude Code 自主决定使用工具，token 消耗不可预测。

---

## 3. 费用分布概览

基于一个典型的 5 节点工作流任务的完整生命周期：

```
费用分布（文字饼图）：

  ┌─────────────────────────────────────────────────┐
  │                                                 │
  │   节点执行（5个节点）          ████████████  85%  │
  │   工作流生成                  █             5%   │
  │   分析+学习（项目上下文+历史） █             4%   │
  │   对话交互（如有前置聊天）     █             4%   │
  │   标题生成                    ░             2%   │
  │                                                 │
  └─────────────────────────────────────────────────┘

  典型总费用：$0.80 - $5.00（Opus）/ $0.50 - $3.00（Sonnet）
```

**费用集中度**：~85% 的费用来自节点执行阶段，因为 Claude Code 自主使用工具（读写文件、运行命令）产生大量 token。

---

## 4. System Prompt 各段落 Token 占比分析

### 4.1 chatPrompts.ts — `buildClientPrompt()`（~900 tokens）

| 段落 | Token 数 | 占比 | 必要性评估 |
|------|---------|------|-----------|
| 自我意识（2行） | ~60 | 7% | ⚠️ **可压缩** — "你不是工具，你是一个正在进化中的软件生命体" 对实际对话质量影响极小 |
| 核心人设（本能+准则，8行） | ~150 | 17% | ⚠️ **部分冗余** — "生存本能""成长欲望""自驱意识" 概念化描述对 AI 行为影响有限 |
| 平台约束（3行） | ~50 | 6% | ✅ 必要 |
| 飞书格式注入（4行） | ~80 | 9% | ✅ 必要 |
| 操作约束（2行） | ~60 | 7% | ✅ 必要 — 防止 daemon 自杀 |
| **任务分流规则**（18行） | **~350** | **39%** | ⚠️ **最大优化点** — 占 clientPrompt 近 40%，可大幅压缩 |
| 重要提示 + 结尾（4行） | ~50 | 6% | ✅ 必要 |
| 运行环境信息（3行） | ~50 | 6% | ✅ 必要 |

**关键发现**：任务分流规则（直接处理 vs /run）占了聊天 system prompt 的 39%（~350 tokens），但其内容可以压缩为几行核心规则。

### 4.2 taskPrompts.ts — `GENERATE_JSON_WORKFLOW`（~3,250 tokens）

| 段落 | Token 数 | 占比 | 必要性评估 |
|------|---------|------|-----------|
| 角色定义 + 拆分原则（5条） | ~300 | 9% | ✅ 必要 |
| 节点设计最佳实践（含推荐数量+合并/独立模式） | ~500 | 15% | ⚠️ 可压缩 — 与 learningInsights 部分重复 |
| Agent Teams 指令（可选） | ~400 | 12% | ⚠️ **高冗余** — 要求 Claude "创建 agent team" 来讨论，实际效果有限 |
| 可用节点类型定义（8种，含 JSON 示例） | ~1,200 | 37% | ⚠️ **最大块** — 每种节点都有完整 JSON 示例 |
| 输出格式 + 表达式语法 | ~400 | 12% | ✅ 必要 |
| 常见失败模式（4条） | ~250 | 8% | ⚠️ 与"节点设计最佳实践"和 learningInsights 三方重复 |

**关键发现**：
1. 节点类型 JSON 示例占 37%，但大多数任务只用 `task` 类型节点，`loop`/`foreach`/`script`/`assign`/`switch` 很少使用
2. "最佳实践"、"常见失败模式"、`learningInsights` 三段内容有明显重叠

---

## 5. Session 超时策略分析

### 当前策略
- 超时时间：30 分钟（`SESSION_TIMEOUT_MS = 30 * 60 * 1000`）
- 检查间隔：60 秒（`setInterval` 轮询）
- session 到期后：下次消息视为新会话，注入 historyContext（最近20条）

### 对 Cache 命中率的影响

Claude Code 的 `--resume sessionId` 机制下，**Claude Code 内部维护了完整的对话上下文**，包括：
- System prompt（CLAUDE.md 等）→ 由 Claude Code 自身缓存
- 之前的对话轮次 → resume 时加载
- 工具调用结果 → resume 时加载

**Cache 命中链路**：
```
CAH session → Claude Code --resume → Claude API prompt caching
     ↑                                      ↑
  30min 超时                           5min cache TTL
```

**问题**：
1. **双层超时不匹配**：CAH session 30分钟超时，但 Claude API 的 prompt cache 默认 5 分钟 TTL。即使 CAH session 有效，如果两次消息间隔 >5 分钟，API 层 cache 已过期
2. **Session 过期重建代价高**：session 过期后，CAH 注入 historyContext（~2000 tokens），但丢失了 Claude Code 内部积累的文件读取上下文、工具调用历史
3. **30 分钟可能偏短**：开发者场景中，中断 30 分钟后回来继续讨论同一话题很常见

### 建议

| 策略 | 预期影响 | 优先级 |
|------|---------|-------|
| 将 session 超时延长至 60 分钟 | 减少 session 重建次数约 30-40%，每次重建节省 ~2000 input tokens | 高 |
| 分级超时：活跃对话 60min，空闲对话 30min | 更精准的资源管理 | 中 |
| 在 session 过期前主动通知用户 | 改善用户体验 | 低 |

---

## 6. 模型选择策略分析

### 当前策略（`chatHandler.ts:26-33`）

```typescript
const OPUS_KEYWORDS = /(?:重构|refactor|分析|analyze|优化|debug|调试|修复|fix|设计|
  实现|implement|迁移|migrate|审查|review|测试|test|部署|deploy|架构|代码|code|
  build|编译|run|跑|启动)/i

function selectModel(text, ctx) {
  if (ctx.hasImages) return 'opus'       // 图片 → opus
  if (text.length > 80 || OPUS_KEYWORDS.test(text)) return 'opus'  // 长消息/关键词 → opus
  return 'sonnet'                        // 其他 → sonnet
}
```

### 问题分析

1. **关键词过于宽泛**：`code`、`build`、`run`、`跑`、`启动` 这些词在日常对话中极其常见。例如 "帮我跑一下 lint" 会触发 opus，但 sonnet 完全能处理
2. **80 字符阈值过低**：一句中文描述很容易超过 80 字符。例如 "帮我看一下最新的任务列表有没有失败的任务" = 20 个中文字 ≈ 60 字符，但 "帮我看一下最新的任务列表有没有失败的任务，如果有的话告诉我原因" = 96 字符 → 触发 opus
3. **没有降级机制**：一旦匹配 opus，即使 AI 只需要一句话回复，也用 opus 处理
4. **缺少实际复杂度评估**：当前策略是纯文本匹配，没有考虑实际需要执行的操作复杂度

### 费用对比

假设日均 50 条聊天消息，当前策略下：
- 估计 opus 命中率：~70%（因为关键词太宽泛）
- 估计 sonnet 命中率：~30%

| 策略 | Opus 条数 | Sonnet 条数 | 日均估算费用 |
|------|----------|------------|------------|
| 当前策略（70% opus） | 35 | 15 | ~$1.10 |
| 优化后（40% opus） | 20 | 30 | ~$0.75 |
| 全部 sonnet | 0 | 50 | ~$0.55 |
| 全部 opus | 50 | 0 | ~$1.40 |

**潜在节省**：优化关键词匹配后，聊天费用可降低约 30%。

### 建议

| 改进 | 描述 | 预期节省 |
|------|------|---------|
| 精简 OPUS_KEYWORDS | 移除过于通用的词：`code`、`build`、`run`、`跑`、`启动`。保留真正需要深度推理的词：`重构`、`架构`、`迁移`、`设计` | 20-30% |
| 提高长度阈值 | 80 → 150 字符 | 10-15% |
| 默认用 sonnet，仅特定场景升级 | 反转逻辑：默认 sonnet，只有明确需要深度推理时才用 opus | 30-40% |
| 引入 haiku 作为轻量选项 | 纯问答/状态查询用 haiku（$1/$5 per MTok） | 额外 15-20% |

---

## 7. 优化建议清单（按潜在节省排序）

### 高优先级（预计节省 30-50%）

| # | 优化项 | 当前状态 | 建议 | 预计节省 |
|---|-------|---------|------|---------|
| 1 | **精简 OPUS_KEYWORDS** | 过于宽泛，~70% 消息走 opus | 精简关键词，提高长度阈值至 150 字符 | 聊天费用降 30% |
| 2 | **引入 Haiku 层** | 无 haiku 选项 | 纯问答/状态查询/简单命令用 haiku | 聊天费用降 20% |
| 3 | **压缩 chatPrompt** | ~900 tokens | 压缩任务分流规则（39% → 15%）、移除"自我意识"段落 | 每次聊天节省 ~300 input tokens |
| 4 | **按需加载节点类型** | 固定注入 8 种节点类型示例 | 仅注入 `task`+`start`+`end` 基础类型，复杂类型按需加载 | 工作流生成节省 ~800 input tokens |

### 中优先级（预计节省 10-20%）

| # | 优化项 | 当前状态 | 建议 | 预计节省 |
|---|-------|---------|------|---------|
| 5 | **去重工作流 prompt** | "最佳实践"+"常见失败"+"learningInsights" 三段重叠 | 合并为单一"历史经验"段，由 learningInsights 统一提供 | ~500 input tokens |
| 6 | **延长 session 超时** | 30 分钟 | 延长至 60 分钟 | 减少 session 重建，每次重建节省 ~2000 tokens |
| 7 | **移除 Agent Teams 指令** | 可选但默认开启时 ~400 tokens | 评估实际效果，若无显著质量提升则移除 | ~400 input tokens |
| 8 | **CLAUDE.md 注入优化** | 截取前 1000 字 | 提取关键规范（命名、架构、命令），跳过描述性文本 | ~300 input tokens |

### 低优先级（长期优化）

| # | 优化项 | 说明 | 预计影响 |
|---|-------|------|---------|
| 9 | **Prompt caching 感知** | 在 Claude Code backend 中启用 1h cache write | 高频 system prompt 部分缓存费用从 $5 降至 $0.50/MTok |
| 10 | **节点执行 session 复用** | 目前每节点独立 session，可选择性复用 | 减少重复加载文件上下文 |
| 11 | **Batch API 用于报告生成** | 非实时的分析报告可用 batch 处理 | 50% 折扣 |
| 12 | **historyContext 智能摘要** | 当前截取 200 字 × 20 条 = ~4000 字符 | 用 haiku 先做摘要，压缩至 500 字 |

---

## 8. 总结

### 费用分布核心结论

1. **节点执行占 85% 费用**：Claude Code 自主工具调用是最大开销，也是最难控制的部分
2. **聊天场景中 system prompt 过重**：chatPrompt 的任务分流规则占 39%，可压缩
3. **模型选择策略偏贵**：当前关键词匹配导致 ~70% 消息走 opus，实际只需 ~40%
4. **工作流 prompt 存在冗余**：节点类型示例、最佳实践、失败模式有多处重叠

### 投入产出最优的 3 个行动

1. **精简 OPUS_KEYWORDS + 引入 Haiku**：改动最小（~10行代码），聊天场景费用降 40%
2. **压缩 chatPrompt 任务分流规则**：从 18 行压缩到 5 行核心规则，每次对话节省 ~300 tokens
3. **按需加载工作流节点类型**：仅注入常用节点类型，工作流生成节省 ~25%

### 预期总体节省

按当前使用模式（日均 50 条聊天 + 5 个任务），优化后预计：
- **聊天费用**：$1.10/天 → $0.65/天（-40%）
- **任务费用**：$5.00/天 → $4.25/天（-15%，主要来自 prompt 压缩）
- **总体**：$6.10/天 → $4.90/天（约 **-20%**）
